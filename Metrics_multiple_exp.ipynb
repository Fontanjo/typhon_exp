{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37c9c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7375efb5",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Table with metrics summary (mean + std)\n",
    "- Create full plot (with multiple subplots)\n",
    "- Possibly: assert to check ass exp uses same dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a70a9550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eccf19f0c20c4f8aa2468a76e96128aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Checkbox(value=False, description='000_old_20230419', layout=Layout(width='600px')), Checkbox(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make sure the path is correct, i.e. change according which experiment we want\n",
    "# root_path = Path('results_atari')\n",
    "root_path = Path('results')\n",
    "\n",
    "experiments = sorted([path.stem for path in root_path.iterdir()])\n",
    "exp_box = [widgets.Checkbox(value=False, description=label, layout=widgets.Layout(width='600px')) for label in experiments]\n",
    "exp_vbox = widgets.VBox(exp_box)\n",
    "display(exp_vbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2117af15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT_FOLDER = root_path / 'paper_3'\n",
    "# assert not os.path.exists(OUTPUT_FOLDER)\n",
    "# os.mkdir(OUTPUT_FOLDER), 'OUTPUT FOLDER ALREADY EXISTS! Delete it or change name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1026f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "metrics_paths = []\n",
    "for checkbox in exp_box:\n",
    "    if checkbox.value == True:\n",
    "        metrics_paths.append((checkbox.description, root_path / checkbox.description / 'run_plot' / 'metrics.csv'))\n",
    "\n",
    "# Get only exp names\n",
    "exps_names = [n for n, _ in metrics_paths]\n",
    "\n",
    "# load dfs and put in a dict with exp name as key\n",
    "dfs = {name: pd.read_csv(mpath) for name, mpath in metrics_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee220d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8127effb45b441e480dac10b8203fb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Checkbox(value=True, description='BUS_SELECTED'), Checkbox(value=True, descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_plot = dfs[exps_names[0]]\n",
    "datasets_checkboxes = [widgets.Checkbox(value=True, description=label) for label in pd.unique(metrics_plot['dataset'])]\n",
    "datasets_vbox = widgets.VBox(children=datasets_checkboxes)\n",
    " \n",
    "metrics_checkboxes = [widgets.Checkbox(value=True, description=label) for label in pd.unique(metrics_plot['metric'])]\n",
    "metrics_vbox = widgets.VBox(children=metrics_checkboxes)\n",
    "\n",
    "split_checkboxes = [widgets.Checkbox(value=True, description=label) for label in ['train', 'validation', 'test']]\n",
    "split_vbox = widgets.VBox(split_checkboxes)\n",
    "\n",
    "\n",
    "vboxes = [datasets_vbox, metrics_vbox, split_vbox]\n",
    "output = widgets.HBox(children=vboxes)\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ea5a0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1score</th>\n",
       "      <th>specificity</th>\n",
       "      <th>iou</th>\n",
       "      <th>dice</th>\n",
       "      <th>hd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20230507_bbbbd3_load_100k_7</th>\n",
       "      <td>0.787124</td>\n",
       "      <td>0.984753</td>\n",
       "      <td>0.795964</td>\n",
       "      <td>0.909400</td>\n",
       "      <td>0.848909</td>\n",
       "      <td>0.988477</td>\n",
       "      <td>0.737482</td>\n",
       "      <td>0.848909</td>\n",
       "      <td>116.759819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20230512_load_bts4_4</th>\n",
       "      <td>0.783326</td>\n",
       "      <td>0.982258</td>\n",
       "      <td>0.765402</td>\n",
       "      <td>0.898824</td>\n",
       "      <td>0.826765</td>\n",
       "      <td>0.986382</td>\n",
       "      <td>0.704688</td>\n",
       "      <td>0.826765</td>\n",
       "      <td>86.722513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20230512_load_bts5_5</th>\n",
       "      <td>0.788183</td>\n",
       "      <td>0.984494</td>\n",
       "      <td>0.805506</td>\n",
       "      <td>0.884313</td>\n",
       "      <td>0.843072</td>\n",
       "      <td>0.989446</td>\n",
       "      <td>0.728716</td>\n",
       "      <td>0.843072</td>\n",
       "      <td>97.799135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 loss  accuracy  precision    recall  \\\n",
       "20230507_bbbbd3_load_100k_7  0.787124  0.984753   0.795964  0.909400   \n",
       "20230512_load_bts4_4         0.783326  0.982258   0.765402  0.898824   \n",
       "20230512_load_bts5_5         0.788183  0.984494   0.805506  0.884313   \n",
       "\n",
       "                              f1score  specificity       iou      dice  \\\n",
       "20230507_bbbbd3_load_100k_7  0.848909     0.988477  0.737482  0.848909   \n",
       "20230512_load_bts4_4         0.826765     0.986382  0.704688  0.826765   \n",
       "20230512_load_bts5_5         0.843072     0.989446  0.728716  0.843072   \n",
       "\n",
       "                                     hd  \n",
       "20230507_bbbbd3_load_100k_7  116.759819  \n",
       "20230512_load_bts4_4          86.722513  \n",
       "20230512_load_bts5_5          97.799135  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get selected dsets\n",
    "dsets = [d.description for d in datasets_checkboxes if d.value == True]\n",
    "# Get selected metrics\n",
    "metrics = [m.description for m in metrics_checkboxes if m.value == True]\n",
    "# Get selected splits (train, validation, test)\n",
    "splits = [c.description for c in split_checkboxes if c.value == True]\n",
    "\n",
    "\n",
    "vals = []\n",
    "# Loop over dsets\n",
    "for dset_name in dsets:\n",
    "    # Loop over type (train, validation, test)\n",
    "    for split in ['test']:#splits:\n",
    "        # Loop over dset\n",
    "        for exp in exps_names:\n",
    "            # Get dataframe\n",
    "            df = dfs[exp]\n",
    "            # Filted dset\n",
    "            df = df[df['dataset'] == dset_name]\n",
    "            # Select split\n",
    "            df_split = df[df['split'] == split]\n",
    "            # Create empty row\n",
    "            row = []\n",
    "            # Loop over metrics\n",
    "            for metric_name in metrics:\n",
    "                # Filter metrics\n",
    "                df_metric = df_split[df_split['metric'] == metric_name]\n",
    "#                 print(df_split[df_split['epoch'] == -1])\n",
    "                df_metric = df_metric[df_metric['epoch'] == -1]\n",
    "                row.append(df_metric['value'].item())\n",
    "            vals.append(row)\n",
    "            \n",
    "#                 # Create row name\n",
    "#                 row_name = f\"{exp}_{dset_name}_{metric_name}\"\n",
    "#                 # Insert in df with new index\n",
    "#                 vs.append(df_split['value'].set_axis(row_name, axis=0).rename(metric_name))\n",
    "#                 values.insert(0, col_name, df_split['value'].set_axis(df_split['epoch'])) # works also\n",
    "# Merge into a single df\n",
    "# values = pd.concat(vs)#, axis=1)\n",
    "# values\n",
    "df_all = pd.DataFrame(vals, index=exps_names, columns=metrics)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e47ebcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  loss       0.7862 +- 0.0026\n",
      "              accuracy       0.9838 +- 0.0014\n",
      "             precision        0.789 +- 0.021\n",
      "                recall       0.8975 +- 0.0126\n",
      "               f1score       0.8396 +- 0.0115\n",
      "           specificity       0.9881 +- 0.0016\n",
      "                   iou       0.7236 +- 0.017\n",
      "                  dice       0.8396 +- 0.0115\n",
      "                    hd     100.4272 +- 15.1901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27048/3605444602.py:1: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for col_name, values in df_all.iteritems():\n"
     ]
    }
   ],
   "source": [
    "for col_name, values in df_all.iteritems():\n",
    "    mn = round(values.mean(), 4)\n",
    "    std = round(values.std(), 4)\n",
    "#     print(f\"{col_name}: {mn} +- {std}\")\n",
    "    print('{:>22}'.format(col_name), '{:>12}'.format(mn), '{:>2}'.format(\"+-\"), '{:2}'.format(std))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f252dea",
   "metadata": {},
   "source": [
    "## Last value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2471d12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_train</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>f1score_train</th>\n",
       "      <th>specificity_train</th>\n",
       "      <th>iou_train</th>\n",
       "      <th>dice_train</th>\n",
       "      <th>hd_train</th>\n",
       "      <th>loss_validation</th>\n",
       "      <th>...</th>\n",
       "      <th>hd_validation</th>\n",
       "      <th>loss_test</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>f1score_test</th>\n",
       "      <th>specificity_test</th>\n",
       "      <th>iou_test</th>\n",
       "      <th>dice_test</th>\n",
       "      <th>hd_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20230507_bbbbd3_load_100k_7</th>\n",
       "      <td>0.639885</td>\n",
       "      <td>0.996492</td>\n",
       "      <td>0.966473</td>\n",
       "      <td>0.996517</td>\n",
       "      <td>0.981265</td>\n",
       "      <td>0.996489</td>\n",
       "      <td>0.963219</td>\n",
       "      <td>0.981265</td>\n",
       "      <td>54.766679</td>\n",
       "      <td>0.701947</td>\n",
       "      <td>...</td>\n",
       "      <td>105.183232</td>\n",
       "      <td>0.781951</td>\n",
       "      <td>0.984509</td>\n",
       "      <td>0.790638</td>\n",
       "      <td>0.912840</td>\n",
       "      <td>0.847356</td>\n",
       "      <td>0.988052</td>\n",
       "      <td>0.735141</td>\n",
       "      <td>0.847356</td>\n",
       "      <td>121.422370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20230512_load_bts4_4</th>\n",
       "      <td>0.644319</td>\n",
       "      <td>0.996101</td>\n",
       "      <td>0.973556</td>\n",
       "      <td>0.984448</td>\n",
       "      <td>0.978972</td>\n",
       "      <td>0.997285</td>\n",
       "      <td>0.958810</td>\n",
       "      <td>0.978972</td>\n",
       "      <td>20.689065</td>\n",
       "      <td>0.705162</td>\n",
       "      <td>...</td>\n",
       "      <td>90.390415</td>\n",
       "      <td>0.788440</td>\n",
       "      <td>0.986376</td>\n",
       "      <td>0.833147</td>\n",
       "      <td>0.888747</td>\n",
       "      <td>0.860050</td>\n",
       "      <td>0.991202</td>\n",
       "      <td>0.754462</td>\n",
       "      <td>0.860050</td>\n",
       "      <td>78.708461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20230512_load_bts5_5</th>\n",
       "      <td>0.639880</td>\n",
       "      <td>0.995567</td>\n",
       "      <td>0.966752</td>\n",
       "      <td>0.985815</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.996557</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>23.157657</td>\n",
       "      <td>0.706566</td>\n",
       "      <td>...</td>\n",
       "      <td>93.774583</td>\n",
       "      <td>0.787784</td>\n",
       "      <td>0.981973</td>\n",
       "      <td>0.770997</td>\n",
       "      <td>0.878092</td>\n",
       "      <td>0.821067</td>\n",
       "      <td>0.987108</td>\n",
       "      <td>0.696450</td>\n",
       "      <td>0.821067</td>\n",
       "      <td>93.320654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             loss_train  accuracy_train  precision_train  \\\n",
       "20230507_bbbbd3_load_100k_7    0.639885        0.996492         0.966473   \n",
       "20230512_load_bts4_4           0.644319        0.996101         0.973556   \n",
       "20230512_load_bts5_5           0.639880        0.995567         0.966752   \n",
       "\n",
       "                             recall_train  f1score_train  specificity_train  \\\n",
       "20230507_bbbbd3_load_100k_7      0.996517       0.981265           0.996489   \n",
       "20230512_load_bts4_4             0.984448       0.978972           0.997285   \n",
       "20230512_load_bts5_5             0.985815       0.976190           0.996557   \n",
       "\n",
       "                             iou_train  dice_train   hd_train  \\\n",
       "20230507_bbbbd3_load_100k_7   0.963219    0.981265  54.766679   \n",
       "20230512_load_bts4_4          0.958810    0.978972  20.689065   \n",
       "20230512_load_bts5_5          0.953488    0.976190  23.157657   \n",
       "\n",
       "                             loss_validation  ...  hd_validation  loss_test  \\\n",
       "20230507_bbbbd3_load_100k_7         0.701947  ...     105.183232   0.781951   \n",
       "20230512_load_bts4_4                0.705162  ...      90.390415   0.788440   \n",
       "20230512_load_bts5_5                0.706566  ...      93.774583   0.787784   \n",
       "\n",
       "                             accuracy_test  precision_test  recall_test  \\\n",
       "20230507_bbbbd3_load_100k_7       0.984509        0.790638     0.912840   \n",
       "20230512_load_bts4_4              0.986376        0.833147     0.888747   \n",
       "20230512_load_bts5_5              0.981973        0.770997     0.878092   \n",
       "\n",
       "                             f1score_test  specificity_test  iou_test  \\\n",
       "20230507_bbbbd3_load_100k_7      0.847356          0.988052  0.735141   \n",
       "20230512_load_bts4_4             0.860050          0.991202  0.754462   \n",
       "20230512_load_bts5_5             0.821067          0.987108  0.696450   \n",
       "\n",
       "                             dice_test     hd_test  \n",
       "20230507_bbbbd3_load_100k_7   0.847356  121.422370  \n",
       "20230512_load_bts4_4          0.860050   78.708461  \n",
       "20230512_load_bts5_5          0.821067   93.320654  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = []\n",
    "# Loop over dsets\n",
    "for dset_name in dsets:\n",
    "    # Loop over dset\n",
    "    for exp in exps_names:\n",
    "        # Create empty row\n",
    "        row = []\n",
    "        cols_names = []\n",
    "        # Loop over type (train, validation, test)\n",
    "        for split in splits:\n",
    "            # Get dataframe\n",
    "            df = dfs[exp]\n",
    "            # Filted dset\n",
    "            df = df[df['dataset'] == dset_name]\n",
    "            # Select split\n",
    "            df_split = df[df['split'] == split]\n",
    "            # Loop over metrics\n",
    "            for metric_name in metrics:\n",
    "                # Filter metrics\n",
    "                df_metric = df_split[df_split['metric'] == metric_name]\n",
    "                # Consider last\n",
    "                if split == 'test':\n",
    "                    df_metric = df_metric.iloc[-2, :]\n",
    "                else:\n",
    "                    df_metric = df_metric.iloc[-1, :]\n",
    "                row.append(df_metric['value'].item())\n",
    "                cols_names.append(f\"{metric_name}_{split}\")\n",
    "        vals.append(row)\n",
    "            \n",
    "#                 # Create row name\n",
    "#                 row_name = f\"{exp}_{dset_name}_{metric_name}\"\n",
    "#                 # Insert in df with new index\n",
    "#                 vs.append(df_split['value'].set_axis(row_name, axis=0).rename(metric_name))\n",
    "#                 values.insert(0, col_name, df_split['value'].set_axis(df_split['epoch'])) # works also\n",
    "# Merge into a single df\n",
    "# values = pd.concat(vs)#, axis=1)\n",
    "# values\n",
    "df_all = pd.DataFrame(vals, index=exps_names, columns=cols_names)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ec2b511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            loss_train       0.6414 +- 0.0026\n",
      "        accuracy_train       0.9961 +- 0.0005\n",
      "       precision_train       0.9689 +- 0.004\n",
      "          recall_train       0.9889 +- 0.0066\n",
      "         f1score_train       0.9788 +- 0.0025\n",
      "     specificity_train       0.9968 +- 0.0004\n",
      "             iou_train       0.9585 +- 0.0049\n",
      "            dice_train       0.9788 +- 0.0025\n",
      "              hd_train      32.8711 +- 19.0022\n",
      "       loss_validation       0.7046 +- 0.0024\n",
      "   accuracy_validation       0.9645 +- 0.0014\n",
      "  precision_validation       0.8031 +- 0.023\n",
      "     recall_validation       0.7217 +- 0.0587\n",
      "    f1score_validation       0.7587 +- 0.0216\n",
      "specificity_validation        0.985 +- 0.0035\n",
      "        iou_validation       0.6116 +- 0.0282\n",
      "       dice_validation       0.7587 +- 0.0216\n",
      "         hd_validation      96.4494 +- 7.7507\n",
      "             loss_test       0.7861 +- 0.0036\n",
      "         accuracy_test       0.9843 +- 0.0022\n",
      "        precision_test       0.7983 +- 0.0318\n",
      "           recall_test       0.8932 +- 0.0178\n",
      "          f1score_test       0.8428 +- 0.0199\n",
      "      specificity_test       0.9888 +- 0.0021\n",
      "              iou_test       0.7287 +- 0.0295\n",
      "             dice_test       0.8428 +- 0.0199\n",
      "               hd_test      97.8172 +- 21.7091\n"
     ]
    }
   ],
   "source": [
    "fmt = '{:10} {:<20} {:<10} {:<20}'\n",
    "for col_name, values in df_all.items():\n",
    "    mn = round(values.mean(), 4)\n",
    "    std = round(values.std(), 4)\n",
    "    print('{:>22}'.format(col_name), '{:>12}'.format(mn), '{:>2}'.format(\"+-\"), '{:2}'.format(std))\n",
    "#     print(fmt.format(col_name, mn, \"+-\", std))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70a5b42",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
