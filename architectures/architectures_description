vgg16 -> https://iq.opengenus.org/vgg16/
  split before the last 3 linear layers

unet -> https://medium.com/analytics-vidhya/unet-implementation-in-pytorch-idiot-developer-da40d955f201
  v0 -> split after the entire recostruction, only one convolution in dm
  v1 -> split before last 1 block of reconstruction
  v2 -> split before last 2 blocks of reconstruction
  v3 -> split before last 3 blocks of reconstruction


                                                         v1       v0
                                                  v2     |        |
                                           v3     |      |        |
  input ---> cnn --------------------------|------|------|- tcnn -|--> output
                  cnn ---------------------|------|- tcnn
                       cnn ----------------|- tcnn
                            cnn ----- tcnn
                                  cnn


  cnn = encoder block, based on Conv2d
  tcnn = decoder block, based on ConvTranspose2d


## AUTOENCODERS ##

AE2Long
  uses conv with stride of 2 to reduce size
  structure: conv2d, batch_norm, relu
  central shape: 128x8x8 (8192)

AE3LongP
  uses max pooling to reduce the size
  structure: conv2d, max_pool, batch_norm, relu
  uses convolution with different kernels: [9, 5, 3, 3, 3, 3, 3]
  central shape: 512x2x2 (2048)

AE3LongerP
  same as AE3Long, but with an additional block at the beginning
   which does not increase the number of channels, but still
   reduces the size
  central shape: 512x1x1 (512)


AE4LongP
  same fe as AE3LongP, but decoder (dm) uses also Conv2d after each ConvTranspose
  central shape: 512x2x2 (2048)

AE5LongP
  similar as AE3LongP, but with only 3x3 kernels



## VARIATIONAL AUTOENCODERS ##
At the center, samples from a distribution

vae2
  based on AE2Long
  uses conv with stride of 2 to reduce size
  structure: conv2d, batch_norm, relu
  additional convolution for mu and var, with stride of 2
  central shape: 128x4x4 (2048)

vae2_mv
  same of vae2, but returns mu and logvar together with the output
  necessary to compute a better loss (BCE + KL-Divergence)

vae3_mv
  uses max pooling to reduce the size
  structure: conv2d, max_pool, batch_norm, relu
  kernels: [9, 5, 3, 3, 3, 3, 3]
  additional convolution for mu and var, with stride of 2
  central shape: 512x1x1 (512)

vae3_nosig_mv
  same as vae3, but without a sigmoid() at the end of the dm
  this is important because after removing the mode, images will have some negative values
  since sigmoid() will only give positive value, it prevents a correct learning

vae5_mv
  same as vae3_mv, but takes an input of shape (210, 160, 3) (the shape of the atari images)
  the fe remains exactly the same
  the output_paddings in the decoder are set in order to reconstruct the correct initial shape
